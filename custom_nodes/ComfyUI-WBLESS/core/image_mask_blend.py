"""
å›¾åƒé®ç½©æ··åˆèŠ‚ç‚¹
Image Mask Blend Node
"""

import torch
import copy
import numpy as np
from PIL import Image, ImageDraw
from cozy_comfyui.node import CozyBaseNode
from .util.blendmodes import BLEND_MODES

# ==================== å·¥å…·å‡½æ•° ====================

def log(message: str, message_type: str = 'info'):
    """
    æ—¥å¿—è¾“å‡ºå‡½æ•°
    
    å‚æ•°:
        message: æ—¥å¿—æ¶ˆæ¯
        message_type: æ¶ˆæ¯ç±»å‹ (info/warning/error/finish)
    """
    name = 'WBLESS'
    
    if message_type == 'error':
        message = '\033[1;41m' + message + '\033[m'
    elif message_type == 'warning':
        message = '\033[1;31m' + message + '\033[m'
    elif message_type == 'finish':
        message = '\033[1;32m' + message + '\033[m'
    else:
        message = '\033[1;33m' + message + '\033[m'
    print(f"# WBLESS: {name} -> {message}")


def pil2tensor(image: Image) -> torch.Tensor:
    """
    å°†PILå›¾åƒè½¬æ¢ä¸ºPyTorchå¼ é‡
    
    å‚æ•°:
        image: PILå›¾åƒå¯¹è±¡
    è¿”å›:
        PyTorchå¼ é‡ï¼Œå½¢çŠ¶ä¸º[1, H, W, C]ï¼Œå€¼èŒƒå›´[0, 1]
    """
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)


def tensor2pil(t_image: torch.Tensor) -> Image:
    """
    å°†PyTorchå¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ
    
    å‚æ•°:
        t_image: PyTorchå¼ é‡
    è¿”å›:
        PILå›¾åƒå¯¹è±¡
    """
    return Image.fromarray(np.clip(255.0 * t_image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))


def image2mask(image: Image) -> torch.Tensor:
    """
    å°†PILå›¾åƒè½¬æ¢ä¸ºé®ç½©å¼ é‡
    
    å‚æ•°:
        image: PILå›¾åƒå¯¹è±¡
    è¿”å›:
        é®ç½©å¼ é‡ï¼Œå½¢çŠ¶ä¸º[1, H, W]
    """
    if image.mode == 'L':
        return torch.tensor([pil2tensor(image)[0, :, :].tolist()])
    else:
        image = image.convert('RGB').split()[0]
        return torch.tensor([pil2tensor(image)[0, :, :].tolist()])


def get_mask_bounds(mask: Image) -> tuple:
    """
    è·å–é®ç½©çš„è¾¹ç•Œæ¡†
    
    å‚æ•°:
        mask: PILç°åº¦é®ç½©å›¾åƒ
    è¿”å›:
        (x, y, width, height) - é®ç½©å†…å®¹çš„è¾¹ç•Œæ¡†ï¼Œå¦‚æœé®ç½©ä¸ºç©ºåˆ™è¿”å› (0, 0, 0, 0)
    """
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    mask_array = np.array(mask)
    
    # æ‰¾åˆ°éé›¶åƒç´ ï¼ˆè€ƒè™‘åˆ°å¯èƒ½æ˜¯è½¯é®ç½©ï¼Œä½¿ç”¨é˜ˆå€¼ï¼‰
    threshold = 1  # å¤§äº1çš„å€¼è¢«è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
    coords = np.argwhere(mask_array > threshold)
    
    if coords.size == 0:
        # é®ç½©ä¸ºç©º
        return (0, 0, 0, 0)
    
    # è·å–è¾¹ç•Œæ¡†
    y_min, x_min = coords.min(axis=0)
    y_max, x_max = coords.max(axis=0)
    
    # è®¡ç®—å®½åº¦å’Œé«˜åº¦
    width = x_max - x_min + 1
    height = y_max - y_min + 1
    
    return (int(x_min), int(y_min), int(width), int(height))


def RGB2RGBA(image: Image, mask: Image) -> Image:
    """
    å°†RGBå›¾åƒå’Œé®ç½©åˆå¹¶ä¸ºRGBAå›¾åƒ
    
    å‚æ•°:
        image: RGBå›¾åƒ
        mask: ç°åº¦é®ç½©
    è¿”å›:
        RGBAå›¾åƒ
    """
    (R, G, B) = image.convert('RGB').split()
    return Image.merge('RGBA', (R, G, B, mask.convert('L')))


def chop_image_v2(background_image: Image, layer_image: Image, blend_mode: str, opacity: int) -> Image:
    """
    åº”ç”¨æ··åˆæ¨¡å¼å°†å›¾å±‚åˆæˆåˆ°èƒŒæ™¯å›¾åƒä¸Š
    
    å‚æ•°:
        background_image: èƒŒæ™¯å›¾åƒ
        layer_image: å›¾å±‚å›¾åƒ
        blend_mode: æ··åˆæ¨¡å¼åç§°
        opacity: ä¸é€æ˜åº¦ (0-100)
    è¿”å›:
        æ··åˆåçš„å›¾åƒ
    """
    backdrop_prepped = np.asarray(background_image.convert('RGBA'), dtype=float)
    source_prepped = np.asarray(layer_image.convert('RGBA'), dtype=float)
    blended_np = BLEND_MODES[blend_mode](backdrop_prepped, source_prepped, opacity / 100)
    
    return Image.fromarray(np.uint8(blended_np)).convert('RGB')


def __rotate_expand(image: Image, angle: float, SSAA: int = 0, method: str = "lanczos") -> Image:
    """
    æ—‹è½¬å›¾åƒå¹¶æ‰©å±•ç”»å¸ƒä»¥é€‚åº”
    æ”¯æŒè¶…é‡‡æ ·æŠ—é”¯é½¿(SSAA)
    
    å‚æ•°:
        image: è¾“å…¥å›¾åƒ
        angle: æ—‹è½¬è§’åº¦
        SSAA: è¶…é‡‡æ ·å€æ•°ï¼Œ0è¡¨ç¤ºç¦ç”¨
        method: é‡é‡‡æ ·æ–¹æ³•
    è¿”å›:
        æ—‹è½¬åçš„å›¾åƒ
    """
    images = pil2tensor(image)
    height, width = images[0, :, :, 0].shape

    def rotate_tensor(tensor):
        # æ ¹æ®æ–¹æ³•é€‰æ‹©é‡é‡‡æ ·ç®—æ³•
        resize_sampler = Image.LANCZOS
        rotate_sampler = Image.BICUBIC
        if method == "bicubic":
            resize_sampler = Image.BICUBIC
            rotate_sampler = Image.BICUBIC
        elif method == "hamming":
            resize_sampler = Image.HAMMING
            rotate_sampler = Image.BILINEAR
        elif method == "bilinear":
            resize_sampler = Image.BILINEAR
            rotate_sampler = Image.BILINEAR
        elif method == "box":
            resize_sampler = Image.BOX
            rotate_sampler = Image.NEAREST
        elif method == "nearest":
            resize_sampler = Image.NEAREST
            rotate_sampler = Image.NEAREST
        
        img = tensor2pil(tensor)
        
        # åº”ç”¨è¶…é‡‡æ ·æŠ—é”¯é½¿
        if SSAA > 1:
            img_us_scaled = img.resize((width * SSAA, height * SSAA), resize_sampler)
            img_rotated = img_us_scaled.rotate(angle, rotate_sampler, expand=True, fillcolor=(0, 0, 0, 0))
            img_down_scaled = img_rotated.resize((img_rotated.width // SSAA, img_rotated.height // SSAA), resize_sampler)
            result = pil2tensor(img_down_scaled)
        else:
            img_rotated = img.rotate(angle, rotate_sampler, expand=True, fillcolor=(0, 0, 0, 0))
            result = pil2tensor(img_rotated)
        return result

    # å¦‚æœè§’åº¦ä¸º0æˆ–360åº¦ï¼Œç›´æ¥è¿”å›åŸå›¾
    if angle == 0.0 or angle == 360.0:
        return tensor2pil(images)
    else:
        rotated_tensor = torch.stack([rotate_tensor(images[i]) for i in range(len(images))])
        return tensor2pil(rotated_tensor).convert('RGB')


def image_rotate_extend_with_alpha(image: Image, angle: float, alpha: Image = None, method: str = "lanczos", SSAA: int = 0) -> tuple:
    """
    æ—‹è½¬å›¾åƒå’ŒAlphaé€šé“
    
    å‚æ•°:
        image: è¾“å…¥å›¾åƒ
        angle: æ—‹è½¬è§’åº¦
        alpha: Alphaé€šé“å›¾åƒ
        method: é‡é‡‡æ ·æ–¹æ³•
        SSAA: è¶…é‡‡æ ·å€æ•°
    è¿”å›:
        (æ—‹è½¬åçš„RGBå›¾åƒ, æ—‹è½¬åçš„Alphaé€šé“, æ—‹è½¬åçš„RGBAå›¾åƒ)
    """
    _image = __rotate_expand(image.convert('RGB'), angle, SSAA, method)
    if alpha is not None:
        _alpha = __rotate_expand(alpha.convert('RGB'), angle, SSAA, method)
        ret_image = RGB2RGBA(_image, _alpha)
    else:
        ret_image = _image
        _alpha = Image.new('L', _image.size, 255)
    return (_image, _alpha.convert('L'), ret_image)


# ä»BLEND_MODESå­—å…¸ç”Ÿæˆå¯ç”¨çš„æ··åˆæ¨¡å¼åˆ—è¡¨
chop_mode_v2 = list(BLEND_MODES.keys())

# ==================== èŠ‚ç‚¹ç±» ====================

class ImageMaskBlend(CozyBaseNode):
    """
    å›¾åƒé®ç½©æ··åˆèŠ‚ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - ä½¿ç”¨ mask çš„è¾¹ç•Œæ¡†æ¥ç¡®å®š layer_image çš„ç¼©æ”¾ç›®æ ‡å°ºå¯¸å’Œä½ç½®
    - å°† layer_image è‡ªåŠ¨ç¼©æ”¾åˆ° mask è¾¹ç•Œæ¡†çš„å¤§å°ï¼ˆCoveræ¨¡å¼ï¼‰
    - ä¿æŒ layer_image çš„åŸå§‹çºµæ¨ªæ¯”ä¸å˜
    - ç¡®ä¿ layer_image å®Œå…¨è¦†ç›– mask è¾¹ç•Œæ¡†åŒºåŸŸï¼ˆå¯ä»¥å¤§äºä½†ä¸èƒ½å°äºï¼‰
    - å°†ç¼©æ”¾åçš„å®Œæ•´å›¾åƒæ··åˆåˆ°èƒŒæ™¯ä¸Šï¼ˆä¸ä½¿ç”¨maskå½¢çŠ¶è£å‰ªï¼‰
    
    ç¼©æ”¾æ¨¡å¼ï¼ˆCoveræ¨¡å¼ï¼‰ï¼š
    - ä¿æŒ layer_image çš„åŸå§‹å®½é«˜æ¯”
    - è®¡ç®—èƒ½å¤Ÿå®Œå…¨è¦†ç›– mask è¾¹ç•Œæ¡†çš„æœ€å°ç¼©æ”¾æ¯”ä¾‹
    - å¦‚æœæ¯”ä¾‹ä¸ä¸€è‡´ï¼Œå…è®¸è¶…å‡º mask è¾¹ç•Œæ¡†
    - ç¡®ä¿ layer_image çš„ä»»ä½•ä¸€è¾¹éƒ½ä¸ä¼šå°äº mask è¾¹ç•Œæ¡†
    
    ä¸»è¦ç‰¹æ€§ï¼š
    - æ”¯æŒ 30+ ç§ Photoshop é£æ ¼çš„æ··åˆæ¨¡å¼
    - è‡ªåŠ¨æ ¹æ® mask è¾¹ç•Œæ¡†å®šä½å’Œç¼©æ”¾
    - æ™ºèƒ½å±…ä¸­å¯¹é½
    - é¢å¤–ç¼©æ”¾æ§åˆ¶
    - æ‰¹å¤„ç†æ”¯æŒ
    
    å‚æ•°è¯´æ˜ï¼š
    - layer_mask: å¿…éœ€ï¼Œç”¨äºç¡®å®šæ··åˆåŒºåŸŸçš„ä½ç½®å’Œå¤§å°
    - blend_mode: æ··åˆæ¨¡å¼ï¼ˆnormal, multiply, screenç­‰ï¼‰
    - scale: åœ¨è‡ªåŠ¨è®¡ç®—çš„åŸºç¡€ä¸Šé¢å¤–ç¼©æ”¾ï¼ˆ1.0 = åˆšå¥½è¦†ç›–maskè¾¹ç•Œæ¡†ï¼‰
    - x_percent/y_percent: ç›¸å¯¹äº mask è¾¹ç•Œæ¡†ä¸­å¿ƒçš„åç§»ç™¾åˆ†æ¯”ï¼ˆ50 = å±…ä¸­å¯¹é½ï¼‰
    - transform_method: é‡é‡‡æ ·æ–¹æ³•ï¼ˆlanczos, bicubicç­‰ï¼‰
    """
    
    NAME = "Image Mask Blend"

    @classmethod
    def INPUT_TYPES(cls):
        method_mode = ['lanczos', 'bicubic', 'hamming', 'bilinear', 'box', 'nearest']
        
        return {
            "required": {
                "background_image": ("IMAGE", ),  # èƒŒæ™¯å›¾åƒï¼ˆç›®æ ‡ç”»å¸ƒï¼‰
                "layer_image": ("IMAGE",),  # å›¾å±‚å›¾åƒï¼ˆå°†è¢«ç¼©æ”¾åˆ°maskå¤§å°ï¼‰
                "layer_mask": ("MASK",),  # é®ç½©ï¼ˆå®šä¹‰æ··åˆåŒºåŸŸçš„ä½ç½®å’Œå¤§å°ï¼‰
                "blend_mode": (chop_mode_v2,),  # æ··åˆæ¨¡å¼ï¼ˆ30+ç§Photoshopé£æ ¼ï¼‰
                "x_percent": ("FLOAT", {"default": 50, "min": -999, "max": 999, "step": 0.01}),  # Xåç§»ç™¾åˆ†æ¯” (50=å±…ä¸­)
                "y_percent": ("FLOAT", {"default": 50, "min": -999, "max": 999, "step": 0.01}),  # Yåç§»ç™¾åˆ†æ¯” (50=å±…ä¸­)
                "scale": ("FLOAT", {"default": 1, "min": 0.01, "max": 100, "step": 0.01}),  # é¢å¤–ç¼©æ”¾å€æ•° (1.0=maskå¤§å°)
                "transform_method": (method_mode,),  # é‡é‡‡æ ·æ–¹æ³•
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = 'blend_images'
    CATEGORY = f"ğŸŒˆWBLESS"

    def blend_images(self, background_image, layer_image, layer_mask,
                    blend_mode, x_percent, y_percent,
                    scale, transform_method
                    ):
        """
        æ‰§è¡ŒåŸºäºé®ç½©è¾¹ç•Œæ¡†çš„å›¾åƒæ··åˆæ“ä½œï¼ˆç®€åŒ–ç‰ˆï¼ŒCoveræ¨¡å¼ç¼©æ”¾ï¼‰
        
        å¤„ç†æµç¨‹:
        1. æ‰¹å¤„ç†å‡†å¤‡ï¼šå°†è¾“å…¥å›¾åƒåˆ†ç¦»ä¸ºç‹¬ç«‹æ‰¹æ¬¡
        2. é®ç½©åˆ†æï¼šè·å–é®ç½©å¹¶è®¡ç®—å…¶è¾¹ç•Œæ¡†
        3. æ™ºèƒ½ç¼©æ”¾ï¼ˆCoveræ¨¡å¼ï¼‰ï¼š
           - ä¿æŒ layer_image çš„åŸå§‹çºµæ¨ªæ¯”
           - è®¡ç®—èƒ½å¤Ÿå®Œå…¨è¦†ç›– mask è¾¹ç•Œæ¡†çš„æœ€å°ç¼©æ”¾æ¯”ä¾‹
           - ç¡®ä¿ layer_image ä¸ä¼šå°äº mask è¾¹ç•Œæ¡†ï¼ˆä»»ä½•ä¸€è¾¹ï¼‰
        4. ç²¾ç¡®å®šä½ï¼šå±…ä¸­å¯¹é½åˆ° mask è¾¹ç•Œæ¡†å¹¶åº”ç”¨åç§»è°ƒæ•´
        5. æ··åˆåˆæˆï¼šä½¿ç”¨æŒ‡å®šæ··åˆæ¨¡å¼å°†å®Œæ•´çš„çŸ©å½¢åŒºåŸŸæ··åˆåˆ°èƒŒæ™¯ä¸Šï¼ˆ100%ä¸é€æ˜åº¦ï¼‰
        6. è¾“å‡ºç»“æœï¼šè¿”å›æ··åˆåçš„å›¾åƒ
        
        æ ¸å¿ƒç‰¹æ€§ï¼š
        - mask ä»…ç”¨äºç¡®å®šä½ç½®å’Œå¤§å°ï¼Œä¸ç”¨äºå½¢çŠ¶è£å‰ª
        - layer_image ä¿æŒåŸå§‹çºµæ¨ªæ¯”ï¼Œè‡ªåŠ¨é€‚é… mask è¾¹ç•Œæ¡†å¤§å°
        - ä½¿ç”¨ Cover æ¨¡å¼ç¡®ä¿å®Œå…¨è¦†ç›–ï¼ˆç±»ä¼¼ CSS object-fit: coverï¼‰
        - è¾“å‡ºå®Œæ•´çš„çŸ©å½¢æ··åˆåŒºåŸŸ
        - å›ºå®š100%ä¸é€æ˜åº¦
        - scale å‚æ•°æ§åˆ¶é¢å¤–ç¼©æ”¾å€æ•°ï¼ˆ1.0 = åˆšå¥½è¦†ç›–ï¼‰
        - x_percent/y_percent æ§åˆ¶åç§»ï¼ˆ50 = å±…ä¸­å¯¹é½ï¼‰
        - æ”¯æŒ 30+ ç§ Photoshop é£æ ¼çš„æ··åˆæ¨¡å¼
        """
        # CozyBaseNode å¯èƒ½ä»¥åˆ—è¡¨å½¢å¼ä¼ é€’æ ‡é‡å‚æ•°ï¼Œéœ€è¦å…ˆæå–
        if isinstance(blend_mode, list):
            blend_mode = blend_mode[0] if blend_mode else "normal"
        if isinstance(x_percent, list):
            x_percent = x_percent[0] if x_percent else 50
        if isinstance(y_percent, list):
            y_percent = y_percent[0] if y_percent else 50
        if isinstance(scale, list):
            scale = scale[0] if scale else 1
        if isinstance(transform_method, list):
            transform_method = transform_method[0] if transform_method else 'lanczos'
        
        b_images = []
        l_images = []
        l_masks = []
        ret_images = []
        
        # åˆ†ç¦»æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªèƒŒæ™¯å›¾åƒ
        for b in background_image:
            b_images.append(torch.unsqueeze(b, 0))
        
        # åˆ†ç¦»æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªå›¾å±‚å›¾åƒ
        for l in layer_image:
            l_images.append(torch.unsqueeze(l, 0))
        
        # å¤„ç†é®ç½©è¾“å…¥
        if isinstance(layer_mask, list):
            if len(layer_mask) > 0:
                layer_mask = layer_mask[0]
            else:
                raise ValueError("layer_mask is empty")
        
        # ç¡®ä¿é®ç½©æœ‰æ­£ç¡®çš„ç»´åº¦
        if layer_mask.dim() == 2:
            layer_mask = torch.unsqueeze(layer_mask, 0)
        
        # è½¬æ¢é®ç½©ä¸ºPILå›¾åƒ
        for m in layer_mask:
            l_masks.append(tensor2pil(torch.unsqueeze(m, 0)).convert('L'))

        # ç¡®å®šæœ€å¤§æ‰¹æ¬¡å¤§å°ï¼Œç”¨äºæ‰¹å¤„ç†
        max_batch = max(len(b_images), len(l_images), len(l_masks))
        
        # å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
        for i in range(max_batch):
            # å¦‚æœæŸä¸ªåˆ—è¡¨å…ƒç´ ä¸è¶³ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªå…ƒç´ 
            background_image = b_images[i] if i < len(b_images) else b_images[-1]
            layer_image = l_images[i] if i < len(l_images) else l_images[-1]
            _mask = l_masks[i] if i < len(l_masks) else l_masks[-1]
            
            # é¢„å¤„ç†ï¼šè½¬æ¢ä¸ºPILå›¾åƒ
            _canvas = tensor2pil(background_image).convert('RGB')
            _layer = tensor2pil(layer_image).convert('RGB')
            
            # ç¡®ä¿é®ç½©æ˜¯ç°åº¦å›¾åƒ
            if _mask.mode != 'L':
                _mask = _mask.convert('L')
            
            # ç¡®ä¿é®ç½©å°ºå¯¸ä¸èƒŒæ™¯å›¾åƒåŒ¹é…
            if _mask.size != _canvas.size:
                log(f"Info: {self.__class__.NAME} resizing mask from {_mask.size} to {_canvas.size}", message_type='info')
                _mask = _mask.resize(_canvas.size, Image.LANCZOS)

            # ===== æ–°é€»è¾‘ï¼šæ ¹æ® mask çš„è¾¹ç•Œæ¡†æ¥ç¼©æ”¾å’Œå®šä½ layer_image =====
            
            # 1. è·å– mask çš„è¾¹ç•Œæ¡†
            mask_x, mask_y, mask_width, mask_height = get_mask_bounds(_mask)
            
            # æ£€æŸ¥ mask æ˜¯å¦ä¸ºç©º
            if mask_width == 0 or mask_height == 0:
                log(f"Warning: {self.__class__.NAME} mask is empty, skipping!", message_type='warning')
                # å¦‚æœ mask ä¸ºç©ºï¼Œç›´æ¥è¿”å›åŸå§‹èƒŒæ™¯
                ret_images.append(pil2tensor(_canvas))
                continue
            
            # 2. è®¡ç®—ç›®æ ‡å°ºå¯¸ - ä½¿ç”¨"cover"æ¨¡å¼ç¼©æ”¾
            # ä¿æŒ layer_image çš„åŸå§‹çºµæ¨ªæ¯”ï¼Œç¡®ä¿å®Œå…¨è¦†ç›– mask åŒºåŸŸ
            
            # è·å– layer_image çš„åŸå§‹å°ºå¯¸
            layer_width = _layer.width
            layer_height = _layer.height
            
            # è®¡ç®— mask çš„ç›®æ ‡å°ºå¯¸ï¼ˆè€ƒè™‘ scale å‚æ•°ï¼‰
            target_mask_width = mask_width * scale
            target_mask_height = mask_height * scale
            
            # è®¡ç®—éœ€è¦çš„ç¼©æ”¾æ¯”ä¾‹ï¼Œä½¿ç”¨"cover"æ¨¡å¼
            # ç¡®ä¿ layer_image è‡³å°‘è¦†ç›–æ•´ä¸ª mask åŒºåŸŸï¼ˆå¯ä»¥å¤§äºä½†ä¸èƒ½å°äºï¼‰
            scale_x = target_mask_width / layer_width
            scale_y = target_mask_height / layer_height
            
            # ä½¿ç”¨è¾ƒå¤§çš„ç¼©æ”¾æ¯”ä¾‹ï¼Œç¡®ä¿å®Œå…¨è¦†ç›–
            cover_scale = max(scale_x, scale_y)
            
            # è®¡ç®—æœ€ç»ˆå°ºå¯¸ï¼ˆä¿æŒ layer_image çš„çºµæ¨ªæ¯”ï¼‰
            final_width = int(layer_width * cover_scale)
            final_height = int(layer_height * cover_scale)
            
            # 3. ç¼©æ”¾ layer_image åˆ°è®¡ç®—å‡ºçš„å°ºå¯¸
            # ä½¿ç”¨é«˜è´¨é‡çš„é‡é‡‡æ ·æ–¹æ³•
            resample_methods = {
                'lanczos': Image.LANCZOS,
                'bicubic': Image.BICUBIC,
                'hamming': Image.HAMMING,
                'bilinear': Image.BILINEAR,
                'box': Image.BOX,
                'nearest': Image.NEAREST
            }
            resample = resample_methods.get(transform_method, Image.LANCZOS)
            _layer_scaled = _layer.resize((final_width, final_height), resample)
            
            # 4. è®¡ç®—æ”¾ç½®ä½ç½®
            # ç”±äºä½¿ç”¨äº†"cover"æ¨¡å¼ï¼Œ_layer_scaled å¯èƒ½æ¯” mask å¤§
            # éœ€è¦å±…ä¸­å¯¹é½ï¼Œä½¿ layer_image è¦†ç›–æ•´ä¸ª mask åŒºåŸŸ
            
            # è®¡ç®—å±…ä¸­å¯¹é½æ—¶çš„åç§»ï¼ˆå¦‚æœ layer å¤§äº maskï¼Œä¼šæœ‰è´Ÿåç§»ï¼‰
            center_offset_x = (int(target_mask_width) - _layer_scaled.width) // 2
            center_offset_y = (int(target_mask_height) - _layer_scaled.height) // 2
            
            # åº”ç”¨ç”¨æˆ·æŒ‡å®šçš„ç™¾åˆ†æ¯”åç§»ï¼ˆç›¸å¯¹äºmaskå°ºå¯¸ï¼‰
            user_offset_x = int((x_percent - 50) / 100 * mask_width)
            user_offset_y = int((y_percent - 50) / 100 * mask_height)
            
            # æœ€ç»ˆä½ç½® = maskä½ç½® + å±…ä¸­åç§» + ç”¨æˆ·åç§»
            final_x = mask_x + center_offset_x + user_offset_x
            final_y = mask_y + center_offset_y + user_offset_y
            
            # 6. è®¡ç®—å®é™…å¯è§çš„åŒºåŸŸï¼ˆå¤„ç†è´Ÿåæ ‡å’Œè¶…å‡ºè¾¹ç•Œçš„æƒ…å†µï¼‰
            visible_x1 = max(0, final_x)
            visible_y1 = max(0, final_y)
            visible_x2 = min(_canvas.width, final_x + _layer_scaled.width)
            visible_y2 = min(_canvas.height, final_y + _layer_scaled.height)
            
            # å¦‚æœå›¾åƒå®Œå…¨è¶…å‡ºç”»å¸ƒèŒƒå›´ï¼Œè·³è¿‡
            if visible_x1 >= visible_x2 or visible_y1 >= visible_y2:
                log(f"Warning: {self.__class__.NAME} layer is completely outside canvas, skipping!", message_type='warning')
                ret_images.append(pil2tensor(_canvas))
                continue
            
            # 7. è®¡ç®—å›¾åƒåœ¨ç”»å¸ƒä¸Šçš„è£å‰ªåŒºåŸŸ
            # å¦‚æœ final_x/y ä¸ºè´Ÿï¼Œéœ€è¦è£å‰ª _layer_scaled çš„èµ·å§‹éƒ¨åˆ†
            crop_x = max(0, -final_x)
            crop_y = max(0, -final_y)
            crop_width = visible_x2 - visible_x1
            crop_height = visible_y2 - visible_y1
            
            # è£å‰ªå‡ºå®é™…è¦æ˜¾ç¤ºçš„å›¾åƒéƒ¨åˆ†
            _layer_cropped = _layer_scaled.crop((crop_x, crop_y, crop_x + crop_width, crop_y + crop_height))
            
            # 8. æå–å¯¹åº”çš„èƒŒæ™¯åŒºåŸŸ
            background_region = _canvas.crop((visible_x1, visible_y1, visible_x2, visible_y2))
            
            # 9. åˆ›å»ºä¸è£å‰ªåŒºåŸŸç›¸åŒå¤§å°çš„å›¾å±‚ç”¨äºæ··åˆ
            layer_for_blend = Image.new("RGB", (crop_width, crop_height))
            layer_for_blend.paste(_layer_cropped, (0, 0))
            
            # 10. åº”ç”¨æ··åˆæ¨¡å¼åˆ°è£å‰ªåŒºåŸŸ
            blended_region = chop_image_v2(background_region, layer_for_blend, blend_mode, 100)
            
            # 11. å°†æ··åˆåçš„åŒºåŸŸç²˜è´´å›ç”»å¸ƒ
            _canvas.paste(blended_region, (visible_x1, visible_y1))
            
            # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            ret_images.append(pil2tensor(_canvas))

        log(f"{self.__class__.NAME} Processed {len(ret_images)} image(s).", message_type='finish')
        return (torch.cat(ret_images, dim=0),)

